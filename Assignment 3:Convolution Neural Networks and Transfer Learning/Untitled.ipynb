{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import silence_tensorflow.auto #silences all tensorflow warnings and logs\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(train_dir):\n",
    "    \"\"\" Increasing # of training samples with random transformations \"\"\"\n",
    "    datagen = image.ImageDataGenerator(\n",
    "        rescale = 1./255,\n",
    "        rotation_range = 40,\n",
    "        width_shift_range = 0.3, \n",
    "        height_shift_range = 0.3,\n",
    "        shear_range = 0.2, \n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        fill_mode = 'nearest')\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size = (150,150),\n",
    "        batch_size = 32, \n",
    "        class_mode = 'categorical'\n",
    "    )\n",
    "    return generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 900 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "directory = \"../data/weather_dataset\"\n",
    "generator = data_augmentation(os.path.join(directory, 'train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/4drtyfjtfy-1.zip'\n",
    "request = requests.get(dataset_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ZipFile(BytesIO(request.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZipFile('../data/dataset2.zip').extractall('../data/weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diabetic_data.csv', 'dataset2.zip', 'parkinsons.data', 'weather_dataset']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_url, data_dir):\n",
    "    \"\"\" retrieve weather dataset and place in data directory \"\"\"\n",
    "    \n",
    "    print(\"Retrieving Dataset\")\n",
    "    request = requests.get(dataset_url)\n",
    "    \n",
    "    file = ZipFile(BytesIO(request.content))\n",
    "    file.extractall(data_dir)\n",
    "    ZipFile(data_dir + '/dataset2.zip').extractall(dataset+url)\n",
    "    \n",
    "    os.remove(data_dir+'/dataset2.zip')\n",
    "    os.remove(dataset_path + \"/dataset2\")\n",
    "    print(\"Succesfullly Retrieved Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = 'https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/4drtyfjtfy-1.zip'\n",
    "data_dir = '../data'\n",
    "get_dataset(dataset_url, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../data/weather_dataset/dataset2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..', 'data', 'weather_dataset', 'dataset2']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.rename(directory, )\n",
    "directory.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_v3/classification/4\")\n",
    "])\n",
    "m.build([None, 299, 299, 3])  # Batch input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
