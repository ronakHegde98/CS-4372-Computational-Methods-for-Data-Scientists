{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Enhanced BackPropogation on Diabetes \n",
    "Objective: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-52736429fc8f>, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-52736429fc8f>\"\u001b[1;36m, line \u001b[1;32m23\u001b[0m\n\u001b[1;33m    dataset_url =\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################################################\n",
    "#   Assignment 2: Neural Network Programming\n",
    "#   This is a starter code in Python 3.6 for a 1-hidden-layer neural network.\n",
    "#   You need to have numpy and pandas installed before running this code.\n",
    "#   Below are the meaning of symbols:\n",
    "#   NeuralNet class init method takes file path as parameter and splits it into train and test part\n",
    "#         - it assumes that the last column will the label (output) column\n",
    "#   h - number of neurons in the hidden layer\n",
    "#   X - vector of features for each instance\n",
    "#   y - output for each instance\n",
    "#   W_hidden - weight matrix connecting input to hidden layer\n",
    "#   Wb_hidden - bias matrix for the hidden layer\n",
    "#   W_output - weight matrix connecting hidden layer to output layer\n",
    "#   Wb_output - bias matrix connecting hidden layer to output layer\n",
    "#   deltaOut - delta for output unit (see slides for definition)\n",
    "#   deltaHidden - delta for hidden unit (see slides for definition)\n",
    "#   other symbols have self-explanatory meaning\n",
    "#   You need to complete all TODO marked sections\n",
    "#   You are free to modify this code in any way you want, but need to mention it in the README file.\n",
    "#\n",
    "#####################################################################################################################\n",
    "\n",
    "dataset_url = \n",
    "class NeuralNet:\n",
    "    def __init__(self, dataFile, header=True, h=4):\n",
    "        #np.random.seed(1)\n",
    "        # train refers to the training dataset\n",
    "        # test refers to the testing dataset\n",
    "        # h represents the number of neurons in the hidden layer\n",
    "        raw_input = pd.read_csv(dataFile)\n",
    "        # TODO: Remember to implement the preprocess method\n",
    "        processed_data = self.preprocess(raw_input)\n",
    "        self.train_dataset, self.test_dataset = train_test_split(processed_data)\n",
    "        ncols = len(self.train_dataset.columns)\n",
    "        nrows = len(self.train_dataset.index)\n",
    "        self.X = self.train_dataset.iloc[:, 0:(ncols -1)].values.reshape(nrows, ncols-1)\n",
    "        self.y = self.train_dataset.iloc[:, (ncols-1)].values.reshape(nrows, 1)\n",
    "        #\n",
    "        # Find number of input and output layers from the dataset\n",
    "        #\n",
    "        input_layer_size = len(self.X[1])\n",
    "        if not isinstance(self.y[0], np.ndarray):\n",
    "            self.output_layer_size = 1\n",
    "        else:\n",
    "            self.output_layer_size = len(self.y[0])\n",
    "\n",
    "        # assign random weights to matrices in network\n",
    "        # number of weights connecting layers = (no. of nodes in previous layer) x (no. of nodes in following layer)\n",
    "        self.W_hidden = 2 * np.random.random((input_layer_size, h)) - 1\n",
    "        self.Wb_hidden = 2 * np.random.random((1, h)) - 1\n",
    "\n",
    "        self.W_output = 2 * np.random.random((h, self.output_layer_size)) - 1\n",
    "        self.Wb_output = np.ones((1, self.output_layer_size))\n",
    "\n",
    "        self.deltaOut = np.zeros((self.output_layer_size, 1))\n",
    "        self.deltaHidden = np.zeros((h, 1))\n",
    "        self.h = h\n",
    "\n",
    "    #\n",
    "    # TODO: I have coded the sigmoid activation function, you need to do the same for tanh and ReLu\n",
    "    #\n",
    "\n",
    "    def __activation(self, x, activation=\"sigmoid\"):\n",
    "        if activation == \"sigmoid\":\n",
    "            self.__sigmoid(self, x)\n",
    "        elif activation == \"tanh\":\n",
    "            self.__tanh(self,x)\n",
    "        elif activation == \"relu\":\n",
    "            self.__relu(self,x)\n",
    "     \n",
    "    \n",
    "    #\n",
    "    # TODO: Define the derivative function for tanh, ReLu and their derivatives\n",
    "    #\n",
    "\n",
    "    def __activation_derivative(self, x, activation=\"sigmoid\"):\n",
    "        if activation == \"sigmoid\":\n",
    "            self.__sigmoid_derivative(self, x)\n",
    "        elif activation == \"tanh\":\n",
    "            self.__tanh_derivative(self,x)\n",
    "        elif activation == \"relu\":\n",
    "            self.__relu_derivative(self,x)\n",
    "\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __tanh(self, x):\n",
    "        #val = (2/(1 + np.exp(-2*x))) -1\n",
    "        #return val\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def __relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    # derivative of sigmoid function, indicates confidence about existing weight\n",
    "\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def __tanh_derivative(self, x):\n",
    "        return 1-(np.tanh(x))**2\n",
    "    \n",
    "    def __relu_derivative(self,x):\n",
    "        return (x>0)*1\n",
    "\n",
    "\n",
    "\n",
    "    # Below is the training function\n",
    "\n",
    "    def train(self, max_iterations=60000, learning_rate=0.25):\n",
    "        for iteration in range(max_iterations):\n",
    "            out = self.forward_pass()\n",
    "            error = 0.5 * np.power((out - self.y), 2)\n",
    "            # TODO: I have coded the sigmoid activation, you have to do the rest\n",
    "            self.backward_pass(out, activation=\"sigmoid\")\n",
    "\n",
    "            update_weight_output = learning_rate * np.dot(self.X_hidden.T, self.deltaOut)\n",
    "            update_weight_output_b = learning_rate * np.dot(np.ones((np.size(self.X, 0), 1)).T, self.deltaOut)\n",
    "\n",
    "            update_weight_hidden = learning_rate * np.dot(self.X.T, self.deltaHidden)\n",
    "            update_weight_hidden_b = learning_rate * np.dot(np.ones((np.size(self.X, 0), 1)).T, self.deltaHidden)\n",
    "\n",
    "            self.W_output += update_weight_output\n",
    "            self.Wb_output += update_weight_output_b\n",
    "            self.W_hidden += update_weight_hidden\n",
    "            self.Wb_hidden += update_weight_hidden_b\n",
    "\n",
    "        print(\"After \" + str(max_iterations) + \" iterations, the total error is \" + str(np.sum(error)))\n",
    "        print(\"The final weight vectors are (starting from input to output layers) \\n\" + str(self.W_hidden))\n",
    "        print(\"The final weight vectors are (starting from input to output layers) \\n\" + str(self.W_output))\n",
    "\n",
    "        print(\"The final bias vectors are (starting from input to output layers) \\n\" + str(self.Wb_hidden))\n",
    "        print(\"The final bias vectors are (starting from input to output layers) \\n\" + str(self.Wb_output))\n",
    "\n",
    "    def forward_pass(self, activation=\"sigmoid\"):\n",
    "        # pass our inputs through our neural network\n",
    "        in_hidden = np.dot(self.X, self.W_hidden) + self.Wb_hidden\n",
    "        # TODO: I have coded the sigmoid activation, you have to do the rest\n",
    "        if activation == \"sigmoid\":\n",
    "            self.X_hidden = self.__sigmoid(in_hidden)\n",
    "        in_output = np.dot(self.X_hidden, self.W_output) + self.Wb_output\n",
    "        if activation == \"sigmoid\":\n",
    "            out = self.__sigmoid(in_output)\n",
    "        return out\n",
    "\n",
    "    def backward_pass(self, out, activation):\n",
    "        # pass our inputs through our neural network\n",
    "        self.compute_output_delta(out, activation)\n",
    "        self.compute_hidden_delta(activation)\n",
    "\n",
    "    # TODO: Implement other activation functions\n",
    "\n",
    "    def compute_output_delta(self, out, activation=\"sigmoid\"):\n",
    "        if activation == \"sigmoid\":\n",
    "            delta_output = (self.y - out) * (self.__sigmoid_derivative(out))\n",
    "\n",
    "        self.deltaOut = delta_output\n",
    "\n",
    "    def compute_hidden_delta(self, activation=\"sigmoid\"):\n",
    "        if activation == \"sigmoid\":\n",
    "            delta_hidden_layer = (self.deltaOut.dot(self.W_output.T)) * (self.__sigmoid_derivative(self.X_hidden))\n",
    "\n",
    "        self.deltaHidden = delta_hidden_layer\n",
    "\n",
    "    # TODO: Implement the predict function for applying the trained model on the  test dataset.\n",
    "    # You can assume that the test dataset has the same format as the training dataset\n",
    "    # You have to output the test error from this function\n",
    "\n",
    "    def predict(self, header = True):\n",
    "        # TODO: obtain prediction on self.test_dataset\n",
    "        return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
