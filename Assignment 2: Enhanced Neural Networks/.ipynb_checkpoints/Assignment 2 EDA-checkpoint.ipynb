{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Neural Network (One Hidden Layer) with Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <b> <u> Dataset background:</u></b> </h2>\n",
    "<ul>\n",
    "    <li>Data: Diabetic Encounters (1-14 days/each) from 130 Hospitals for 10 years (1999-2008) </li>\n",
    "    <li>Goal: Predict if a diabetic patient will be readmitted to a hospital (less than 30 days, after 30 days, or never)</li>\n",
    "    <li>Target Feature: readmitted </li>\n",
    "    <li> <a href = \"https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008\">Dataset Source</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all required libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#display all columns of dataframe\n",
    "pd.pandas.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset Shape: (101766, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>payer_code</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>max_glu_serum</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>metformin</th>\n",
       "      <th>repaglinide</th>\n",
       "      <th>nateglinide</th>\n",
       "      <th>chlorpropamide</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>acetohexamide</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>tolbutamide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>acarbose</th>\n",
       "      <th>miglitol</th>\n",
       "      <th>troglitazone</th>\n",
       "      <th>tolazamide</th>\n",
       "      <th>examide</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>80218</td>\n",
       "      <td>247042512</td>\n",
       "      <td>88533495</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>BC</td>\n",
       "      <td>Emergency/Trauma</td>\n",
       "      <td>68</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>428</td>\n",
       "      <td>518</td>\n",
       "      <td>250.42</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101382</td>\n",
       "      <td>438525890</td>\n",
       "      <td>40711671</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>MC</td>\n",
       "      <td>?</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>414</td>\n",
       "      <td>786</td>\n",
       "      <td>425</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56463</td>\n",
       "      <td>162110298</td>\n",
       "      <td>86376672</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>MC</td>\n",
       "      <td>InternalMedicine</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>486</td>\n",
       "      <td>428</td>\n",
       "      <td>427</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68576</td>\n",
       "      <td>193669110</td>\n",
       "      <td>43385490</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>MC</td>\n",
       "      <td>?</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>569</td>\n",
       "      <td>285</td>\n",
       "      <td>250</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Down</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12375</td>\n",
       "      <td>50407170</td>\n",
       "      <td>1294047</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>Orthopedics-Reconstructive</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>722</td>\n",
       "      <td>250</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        encounter_id  patient_nbr             race  gender      age weight  \\\n",
       "80218      247042512     88533495        Caucasian    Male  [40-50)      ?   \n",
       "101382     438525890     40711671        Caucasian    Male  [70-80)      ?   \n",
       "56463      162110298     86376672        Caucasian    Male  [70-80)      ?   \n",
       "68576      193669110     43385490        Caucasian  Female  [70-80)      ?   \n",
       "12375       50407170      1294047  AfricanAmerican    Male  [40-50)      ?   \n",
       "\n",
       "        admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "80218                   2                         6                    7   \n",
       "101382                  1                         1                    7   \n",
       "56463                   2                         1                    7   \n",
       "68576                   1                         6                    7   \n",
       "12375                   3                         1                    1   \n",
       "\n",
       "        time_in_hospital payer_code           medical_specialty  \\\n",
       "80218                  5         BC            Emergency/Trauma   \n",
       "101382                 1         MC                           ?   \n",
       "56463                 12         MC            InternalMedicine   \n",
       "68576                  2         MC                           ?   \n",
       "12375                  1          ?  Orthopedics-Reconstructive   \n",
       "\n",
       "        num_lab_procedures  num_procedures  num_medications  \\\n",
       "80218                   68               6               38   \n",
       "101382                  44               0               17   \n",
       "56463                   86               1               31   \n",
       "68576                   52               2                9   \n",
       "12375                   51               1               10   \n",
       "\n",
       "        number_outpatient  number_emergency  number_inpatient diag_1 diag_2  \\\n",
       "80218                   2                 0                 8    428    518   \n",
       "101382                  0                 0                 1    414    786   \n",
       "56463                   0                 0                 0    486    428   \n",
       "68576                   0                 0                 0    569    285   \n",
       "12375                   0                 0                 0    722    250   \n",
       "\n",
       "        diag_3  number_diagnoses max_glu_serum A1Cresult metformin  \\\n",
       "80218   250.42                 9          None      None        No   \n",
       "101382     425                 9          None      None        Up   \n",
       "56463      427                 9          None      None    Steady   \n",
       "68576      250                 6          None      None        No   \n",
       "12375        ?                 2          None      None    Steady   \n",
       "\n",
       "       repaglinide nateglinide chlorpropamide glimepiride acetohexamide  \\\n",
       "80218           No          No             No          No            No   \n",
       "101382          No          No             No          No            No   \n",
       "56463           No          No             No          No            No   \n",
       "68576           No          No             No          No            No   \n",
       "12375           No          No             No          No            No   \n",
       "\n",
       "       glipizide glyburide tolbutamide pioglitazone rosiglitazone acarbose  \\\n",
       "80218         No        No          No           No            No       No   \n",
       "101382        No    Steady          No           No            No       No   \n",
       "56463         No        No          No           No        Steady       No   \n",
       "68576     Steady        No          No           No            No       No   \n",
       "12375         No        No          No           No            No       No   \n",
       "\n",
       "       miglitol troglitazone tolazamide examide citoglipton insulin  \\\n",
       "80218        No           No         No      No          No      Up   \n",
       "101382       No           No         No      No          No      No   \n",
       "56463        No           No         No      No          No      No   \n",
       "68576        No           No         No      No          No    Down   \n",
       "12375        No           No         No      No          No  Steady   \n",
       "\n",
       "       glyburide-metformin glipizide-metformin glimepiride-pioglitazone  \\\n",
       "80218                   No                  No                       No   \n",
       "101382                  No                  No                       No   \n",
       "56463                   No                  No                       No   \n",
       "68576                   No                  No                       No   \n",
       "12375                   No                  No                       No   \n",
       "\n",
       "       metformin-rosiglitazone metformin-pioglitazone change diabetesMed  \\\n",
       "80218                       No                     No     Ch         Yes   \n",
       "101382                      No                     No     Ch         Yes   \n",
       "56463                       No                     No     Ch         Yes   \n",
       "68576                       No                     No     Ch         Yes   \n",
       "12375                       No                     No     Ch         Yes   \n",
       "\n",
       "       readmitted  \n",
       "80218         >30  \n",
       "101382         NO  \n",
       "56463          NO  \n",
       "68576         >30  \n",
       "12375          NO  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset \n",
    "dataset_url = \"https://raw.githubusercontent.com/ronakHegde98/CS-4372-Computational-Methods-for-Data-Scientists/master/data/diabetic_data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "print(f\"Initial Dataset Shape: {df.shape}\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16773 patients with multiple records\n"
     ]
    }
   ],
   "source": [
    "## check if patients have multiple records\n",
    "print(f\"There are {np.sum(df['patient_nbr'].value_counts() > 1)} patients with multiple records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 categorical columns and 13 numerical columns\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [col for col in df.columns if df[col].dtype == np.dtype(np.object)]\n",
    "print(f\"There are {len(categorical_cols)} categorical columns and {len(df.columns)-len(categorical_cols)} numerical columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Handling Missing Values </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 192849 '?' values in our dataset which is approx 3.79% of our entire dataset\n"
     ]
    }
   ],
   "source": [
    "## sum all missing values for each row of df (axis 0 is row)\n",
    "missing_count = np.sum(np.sum(np.equal(df, '?'), axis=0))\n",
    "print(f\"There are {missing_count} '?' values in our dataset which is approx {np.round((missing_count/(np.multiply(df.shape[0], df.shape[1])))*100,2)}% of our entire dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert ?'s into np.nan\n",
    "df.replace(\"?\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing data\n",
      " race: 2273\n",
      " weight: 98569\n",
      " payer_code: 40256\n",
      " medical_specialty: 49949\n",
      " diag_1: 21\n",
      " diag_2: 358\n",
      " diag_3: 1423\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns with missing data\")\n",
    "missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "for col in missing_cols:\n",
    "    print(' ' + col + ': ' + str(df[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop rows where gender is Unknown/Invalid\n",
    "df.drop(df[df['gender'] == \"Unknown/Invalid\"].index, axis=0, inplace=True)\n",
    "\n",
    "## dropping columns that have many missing values\n",
    "dropped_columns = ['weight', 'payer_code', 'medical_specialty']\n",
    "dropped_columns.append(\"encounter_id\")\n",
    "dropped_columns.append('discharge_disposition_id')\n",
    "\n",
    "## dropping columns that have little to no variability\n",
    "for col in categorical_cols:\n",
    "    if(df[col].value_counts(normalize=True).max() > 0.948):\n",
    "        dropped_columns.append(col)\n",
    "        \n",
    "df.drop(columns=dropped_columns, axis=1, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Some Patients have multiple records </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one record per patient (where they had max of time_in_hospital)\n",
    "df = df.loc[df.groupby(\"patient_nbr\", sort=False)['time_in_hospital'].idxmax()]\n",
    "df.drop(columns = ['patient_nbr'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## convert our categorical variable (if readmitted -> 1 else 0)\n",
    "df['readmitted'] = np.where(df['readmitted']!='NO',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert age ranges to the midpoint of the ranges\n",
    "new_ages = {\n",
    "    \"[0-10)\": 5,\n",
    "    \"[10-20)\": 15,\n",
    "    \"[20-30)\": 25,\n",
    "    \"[30-40)\": 35,\n",
    "    \"[40-50)\": 45,\n",
    "    \"[50-60)\": 55,\n",
    "    \"[60-70)\": 65,\n",
    "    \"[70-80)\": 75,\n",
    "    \"[80-90)\": 85,\n",
    "    \"[90-100)\": 95\n",
    "}\n",
    "\n",
    "df['age'] = df['age'].map(new_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_glu_serums = {\n",
    "    \"None\": 0,\n",
    "    \"Norm\": 100,\n",
    "    \">200\": 200,\n",
    "    \">300\": 300\n",
    "}\n",
    "df['max_glu_serum'] = df['max_glu_serum'].map(max_glu_serums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1CResult_map = {\n",
    "    \"None\": 0,\n",
    "    \"Norm\": 5,\n",
    "    \">7\": 7,\n",
    "    \">8\": 8\n",
    "}\n",
    "df['A1Cresult'] = df['A1Cresult'].map(A1CResult_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting binary variables into -1 or 1\n",
    "df['change'] = np.where(df['change']=='No',-1,1)\n",
    "df['diabetesMed'] = np.where(df['diabetesMed']=='No',-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_codes = {\n",
    "    \"No\": -20,\n",
    "    \"Down\": -10, \n",
    "    \"Steady\": 0,\n",
    "    \"Up\": 10    \n",
    "}\n",
    "drugs = ['metformin','glipizide','glyburide', 'pioglitazone', 'rosiglitazone','insulin'] \n",
    "for drug in drugs:\n",
    "    df[drug] = df[drug].map(drug_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## mapping diagnosis categories according to paper (else 800 plus features)\n",
    "diagnosis_cols = ['diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "for col in diagnosis_cols:\n",
    "    df['tmp'] = np.nan\n",
    "    df.loc[(df[col].str.contains(\"250\")), col] = '250'\n",
    "    df.loc[(df[col].str.startswith('V')) | (df[col].str.startswith('E')), col] = '-999' \n",
    "\n",
    "    df[col] = df[col].astype(float)\n",
    "    \n",
    "    #convert the correct ranges based on values given in paper\n",
    "    df.loc[(((df[col] >=390) & (df[col]<=460)) | (df[col] == 785)), 'tmp'] = 'Circulatory'\n",
    "    df.loc[(((df[col] >=460) & (df[col]<=519)) | (df[col] == 786)), 'tmp'] = 'Respiratory'\n",
    "    df.loc[(((df[col] >=520) & (df[col]<=579)) | (df[col] == 787)), 'tmp'] = 'Digestive'\n",
    "    df.loc[(((df[col] >=580) & (df[col]<=629)) | (df[col] == 788)), 'tmp'] = 'Genitourinary'\n",
    "    df.loc[((df[col] >=800) & (df[col]<=999)), 'tmp'] = 'Injury'\n",
    "    df.loc[((df[col] >=710) & (df[col]<=739)), 'tmp'] = 'Musculoskeletal'\n",
    "    df.loc[((df[col] >=140) & (df[col]<=239)), 'tmp'] = 'Neoplasms'\n",
    "    df.loc[(df[col] == 250), 'tmp'] = 'Diabetes'\n",
    "    \n",
    "    df['tmp'].fillna(value = \"Other\", inplace=True)\n",
    "    \n",
    "    df[col] = df['tmp']\n",
    "    df.drop(columns=['tmp'], inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## admission_source_id\n",
    "df['tmp'] = np.nan\n",
    "col = 'admission_source_id'\n",
    "df.loc[((df[col].between(4,6)) | (df[col] == 10) | (df[col] == 18) | (df[col] == 22) | (df[col].between(25,26))), 'tmp'] = \"Transfer_Source\"\n",
    "df.loc[df[col].between(1,3), 'tmp'] = \"Referral_Source\"\n",
    "df.loc[((df[col].between(11,14))| (df[col].between(23,24))), 'tmp'] = \"Birth_Source\"\n",
    "df.loc[df[col] == 7, 'tmp'] = \"Emergency_Source\"\n",
    "df.loc[((df[col] == 8) | (df[col]==19)), 'tmp'] = \"Other\"\n",
    "        \n",
    "df['tmp'].fillna(value = \"Unknown\", inplace=True)\n",
    "df[col] = df['tmp']\n",
    "df.drop(columns=['tmp'], inplace=True)\n",
    "\n",
    "\n",
    "##mapping admission type_id\n",
    "df['tmp'] = np.nan\n",
    "col = 'admission_type_id'\n",
    "df.loc[df[col] == 1, 'tmp'] = 'Emergency_Type'\n",
    "df.loc[df[col] == 2, 'tmp'] = 'Urgent_Type'\n",
    "df.loc[df[col] == 3, 'tmp'] = 'Elective_Type'\n",
    "df.loc[df[col] == 7, 'tmp'] = 'Trauma_Type'\n",
    "df.loc[df[col] == 4, 'tmp'] = 'Newborn_Type'\n",
    "\n",
    "df['tmp'].fillna(value = \"Unknown\", inplace=True)\n",
    "df[col] = df['tmp']\n",
    "df.drop(columns=['tmp'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, cols):\n",
    "    \"\"\"one-hot encoding function for all our categorical columns\"\"\"\n",
    "    \n",
    "    for col in cols:\n",
    "        if(\"admission\" in col):\n",
    "            dummies = pd.get_dummies(df[col], drop_first=False)\n",
    "        else:\n",
    "            dummies = pd.get_dummies(df[col], prefix=col, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)   \n",
    "        df.drop([col],axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding \n",
    "categorical_columns = [col for col in df.columns if df[col].dtype == np.dtype(object)]\n",
    "df = one_hot_encoder(df, categorical_columns)\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "#train-test-split\n",
    "target_variable = 'readmitted'\n",
    "Y_feature = df[target_variable]\n",
    "X_features = df.drop(columns=[target_variable])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features,Y_feature, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize of numerical columns\n",
    "mm_scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(mm_scaler.fit_transform(X_train), columns = X_train.columns) \n",
    "X_test = pd.DataFrame(mm_scaler.fit_transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.values.reshape(y_train.shape[0],1)\n",
    "y_test = y_test.values.reshape(y_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class NeuralNet:\n",
    "\n",
    "    def __init__(self, X_train, y_train, h=4):\n",
    "        #np.random.seed(1)\n",
    "        # h represents the number of neurons in the hidden layers\n",
    "        self.X = X_train\n",
    "        self.y = y_train\n",
    "\n",
    "        # Find number of input and output layers from the dataset\n",
    "        input_layer_size = self.X.shape[0]\n",
    "        \n",
    "        \n",
    "        self.output_layer_size = 1\n",
    "\n",
    "        # assign random weights to matrices in network\n",
    "        # number of weights connecting layers = (no. of nodes in previous layer) x (no. of nodes in following layer)\n",
    "        self.W_hidden = 2 * np.random.random((h, input_layer_size)) - 1\n",
    "        self.Wb_hidden = 2 * np.random.random((h,1)) - 1\n",
    "\n",
    "        self.W_output = 2 * np.random.random((self.output_layer_size,h)) - 1\n",
    "        self.Wb_output = np.ones((self.output_layer_size,1))\n",
    "\n",
    "        self.deltaOut = np.zeros((self.output_layer_size, 1))\n",
    "        self.deltaHidden = np.zeros((h, 1))\n",
    "        self.h = h\n",
    "            \n",
    "\n",
    "    def __activation(self, x, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            self.__sigmoid(self, x)\n",
    "        elif activation == \"tanh\":\n",
    "            self.__tanh(self,x)\n",
    "        elif activation == \"relu\":\n",
    "            self.__relu(self,x)\n",
    "     \n",
    "\n",
    "    def __activation_derivative(self, x, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            self.__sigmoid_derivative(self, x)\n",
    "        elif activation == \"tanh\":\n",
    "            self.__tanh_derivative(self,x)\n",
    "        elif activation == \"relu\":\n",
    "            self.__relu_derivative(self,x)\n",
    "\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def __relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def __tanh_derivative(self, x):\n",
    "        return 1-(np.tanh(x))**2\n",
    "    \n",
    "    def __relu_derivative(self,x):\n",
    "        return (x>0)*1\n",
    "\n",
    "\n",
    "    # Below is the training function\n",
    "    def train(self, activation, max_iterations=100, learning_rate=0.00001, momentum = 0.90):\n",
    "        \n",
    "        update_weight_output, update_weight_output_b, update_weight_hidden, update_weight_hidden_b = 0,0,0,0\n",
    "        \n",
    "        for iteration in range(max_iterations):\n",
    "            out = self.forward_pass(activation)\n",
    "            \n",
    "            error = 0.5 * np.power((out - self.y), 2)\n",
    "            \n",
    "            \n",
    "            self.past_delta = [deepcopy(update_weight_output),\n",
    "                                        deepcopy(update_weight_output_b),\n",
    "                                        deepcopy(update_weight_hidden),\n",
    "                                        deepcopy(update_weight_hidden_b)]\n",
    "            \n",
    "            \n",
    "            self.backward_pass(out, activation)\n",
    "            \n",
    "            update_weight_output = learning_rate * (1-momentum) * np.dot(self.deltaOut,self.X_hidden.T) + momentum*self.past_delta[0]\n",
    "            \n",
    "            update_weight_output_b = learning_rate * (1-momentum) * np.dot(self.deltaOut, np.ones((np.size(self.X, 1), 1))) + momentum*self.past_delta[1]\n",
    "            \n",
    "            update_weight_hidden = learning_rate * (1-momentum)* np.dot(self.deltaHidden,self.X.T) + momentum*self.past_delta[2]\n",
    "            \n",
    "            update_weight_hidden_b = learning_rate * (1-momentum)* np.dot(self.deltaHidden,np.ones((np.size(self.X, 1), 1))) + momentum*self.past_delta[3]\n",
    "\n",
    "            self.W_output += update_weight_output\n",
    "            self.Wb_output += update_weight_output_b\n",
    "            self.W_hidden += update_weight_hidden\n",
    "            self.Wb_hidden += update_weight_hidden_b\n",
    "            \n",
    "\n",
    "        print(\"After \" + str(max_iterations) + \" iterations, the total error is \" + str(np.average(np.sum(error))))\n",
    "#         print(\"The final weight vectors are (starting from input to output layers) \\n\" + str(self.W_hidden))\n",
    "#         print(\"The final weight vectors are (starting from input to output layers) \\n\" + str(self.W_output))\n",
    "\n",
    "#         print(\"The final bias vectors are (starting from input to output layers) \\n\" + str(self.Wb_hidden))\n",
    "#         print(\"The final bias vectors are (starting from input to output layers) \\n\" + str(self.Wb_output))\n",
    "\n",
    "    def forward_pass(self, activation):\n",
    "        # pass our inputs through our neural network\n",
    "        in_hidden = np.dot(self.W_hidden, self.X) + self.Wb_hidden\n",
    "\n",
    "        if activation == \"sigmoid\":\n",
    "            self.X_hidden = self.__sigmoid(in_hidden)\n",
    "        elif activation == \"tanh\":\n",
    "            self.X_hidden = self.__tanh(in_hidden)\n",
    "        elif activation == \"relu\":\n",
    "            self.X_hidden = self.__relu(in_hidden)\n",
    "\n",
    "        in_output = np.dot(self.W_output, self.X_hidden) + self.Wb_output\n",
    "        \n",
    "        # output \n",
    "        if activation == \"sigmoid\":\n",
    "            out = self.__sigmoid(in_output)\n",
    "        elif activation == \"tanh\":\n",
    "            out = self.__tanh(in_output)\n",
    "        elif activation == \"relu\":\n",
    "            out = self.__relu(in_output)\n",
    "        return out\n",
    "\n",
    "    def backward_pass(self, out, activation):\n",
    "        # pass our inputs through our neural network\n",
    "        self.compute_output_delta(out, activation)\n",
    "        self.compute_hidden_delta(activation)\n",
    "        \n",
    "\n",
    "\n",
    "    def compute_output_delta(self, out, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            delta_output = (self.y - out) * (self.__sigmoid_derivative(out))\n",
    "        elif activation == \"tanh\":\n",
    "            delta_output = (self.y - out) * (self.__tanh_derivative(out))\n",
    "        elif activation == \"relu\":\n",
    "            delta_output = (self.y - out) * (self.__relu_derivative(out))\n",
    "\n",
    "        self.deltaOut = delta_output\n",
    "\n",
    "    def compute_hidden_delta(self, activation):\n",
    "        \n",
    "        if activation == \"sigmoid\":\n",
    "            delta_hidden_layer = (self.W_output.T.dot(self.deltaOut)) * (self.__sigmoid_derivative(self.X_hidden))\n",
    "        elif activation == \"tanh\":\n",
    "            delta_hidden_layer = (self.W_output.T.dot(self.deltaOut)) * (self.__tanh_derivative(self.X_hidden))\n",
    "        elif activation == \"relu\":\n",
    "            delta_hidden_layer = (self.W_output.T.dot(self.deltaOut)) * (self.__relu_derivative(self.X_hidden))\n",
    "        \n",
    "        self.deltaHidden = delta_hidden_layer\n",
    "\n",
    "\n",
    "    def predict(self, X_test, y_test, activation):\n",
    "        print(\"inside predict\")\n",
    "        predict_hidden = np.dot(self.W_hidden, X_test) + self.Wb_hidden\n",
    "        \n",
    "        self.X_hidden = self.__relu(predict_hidden)\n",
    "        \n",
    "        if(activation == \"sigmoid\"):\n",
    "            self.X_hidden = self.__sigmoid(predict_hidden)\n",
    "        elif(activation==\"relu\"):\n",
    "            self.X_hidden = self.__relu(predict_hidden)\n",
    "        elif(activation == \"tanh\"):\n",
    "            self.X_hidden = self.__tanh(predict_hidden)\n",
    "        \n",
    "        predict_output = np.dot(self.W_output, self.X_hidden) + self.Wb_output\n",
    "        \n",
    "        if(activation == \"sigmoid\"):\n",
    "            out = self.__sigmoid(predict_output)\n",
    "        elif(activation==\"relu\"):\n",
    "            out = self.__relu(predict_output)\n",
    "        elif(activation == \"tanh\"):\n",
    "            out = self.__tanh(predict_output)\n",
    "        \n",
    "        \n",
    "        error = 0.5 * np.power((out - y_test), 2)\n",
    "        print(f\"Error on Test Dataset is {np.sum(error)}\")\n",
    "        return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for iteration 0 is 9503.728045576492\n",
      "Error for iteration 1 is 9503.72770436775\n",
      "Error for iteration 2 is 9503.727056257449\n",
      "Error for iteration 3 is 9503.72613227508\n",
      "Error for iteration 4 is 9503.724960470958\n",
      "Error for iteration 5 is 9503.72356619035\n",
      "Error for iteration 6 is 9503.721972324678\n",
      "Error for iteration 7 is 9503.720199541183\n",
      "Error for iteration 8 is 9503.718266492631\n",
      "Error for iteration 9 is 9503.716190008381\n",
      "Error for iteration 10 is 9503.713985268332\n",
      "Error for iteration 11 is 9503.71166596102\n",
      "Error for iteration 12 is 9503.709244427222\n",
      "Error for iteration 13 is 9503.706731790218\n",
      "Error for iteration 14 is 9503.704138073886\n",
      "Error for iteration 15 is 9503.701472309665\n",
      "Error for iteration 16 is 9503.698742633393\n",
      "Error for iteration 17 is 9503.695956372907\n",
      "Error for iteration 18 is 9503.69312012725\n",
      "Error for iteration 19 is 9503.69023983827\n",
      "Error for iteration 20 is 9503.687320855288\n",
      "Error for iteration 21 is 9503.684367993501\n",
      "Error for iteration 22 is 9503.68138558671\n",
      "Error for iteration 23 is 9503.678377534907\n",
      "Error for iteration 24 is 9503.675347347196\n",
      "Error for iteration 25 is 9503.672298180521\n",
      "Error for iteration 26 is 9503.669232874594\n",
      "Error for iteration 27 is 9503.666153983375\n",
      "Error for iteration 28 is 9503.663063803448\n",
      "Error for iteration 29 is 9503.659964399618\n",
      "Error for iteration 30 is 9503.656857627964\n",
      "Error for iteration 31 is 9503.653745156602\n",
      "Error for iteration 32 is 9503.65062848441\n",
      "Error for iteration 33 is 9503.647508957896\n",
      "Error for iteration 34 is 9503.644387786371\n",
      "Error for iteration 35 is 9503.641266055645\n",
      "Error for iteration 36 is 9503.638144740335\n",
      "Error for iteration 37 is 9503.63502471497\n",
      "Error for iteration 38 is 9503.631906763983\n",
      "Error for iteration 39 is 9503.628791590705\n",
      "Error for iteration 40 is 9503.625679825473\n",
      "Error for iteration 41 is 9503.622572032911\n",
      "Error for iteration 42 is 9503.619468718514\n",
      "Error for iteration 43 is 9503.616370334557\n",
      "Error for iteration 44 is 9503.613277285405\n",
      "Error for iteration 45 is 9503.610189932324\n",
      "Error for iteration 46 is 9503.607108597784\n",
      "Error for iteration 47 is 9503.604033569349\n",
      "Error for iteration 48 is 9503.600965103164\n",
      "Error for iteration 49 is 9503.597903427111\n",
      "Error for iteration 50 is 9503.594848743638\n",
      "Error for iteration 51 is 9503.591801232305\n",
      "Error for iteration 52 is 9503.58876105209\n",
      "Error for iteration 53 is 9503.585728343436\n",
      "Error for iteration 54 is 9503.582703230137\n",
      "Error for iteration 55 is 9503.579685820989\n",
      "Error for iteration 56 is 9503.576676211298\n",
      "Error for iteration 57 is 9503.573674484256\n",
      "Error for iteration 58 is 9503.570680712137\n",
      "Error for iteration 59 is 9503.567694957404\n",
      "Error for iteration 60 is 9503.564717273712\n",
      "Error for iteration 61 is 9503.561747706766\n",
      "Error for iteration 62 is 9503.558786295156\n",
      "Error for iteration 63 is 9503.555833071057\n",
      "Error for iteration 64 is 9503.552888060882\n",
      "Error for iteration 65 is 9503.549951285866\n",
      "Error for iteration 66 is 9503.547022762592\n",
      "Error for iteration 67 is 9503.544102503467\n",
      "Error for iteration 68 is 9503.54119051714\n",
      "Error for iteration 69 is 9503.538286808893\n",
      "Error for iteration 70 is 9503.535391380978\n",
      "Error for iteration 71 is 9503.532504232933\n",
      "Error for iteration 72 is 9503.529625361858\n",
      "Error for iteration 73 is 9503.526754762674\n",
      "Error for iteration 74 is 9503.52389242833\n",
      "Error for iteration 75 is 9503.521038350029\n",
      "Error for iteration 76 is 9503.518192517398\n",
      "Error for iteration 77 is 9503.515354918653\n",
      "Error for iteration 78 is 9503.512525540751\n",
      "Error for iteration 79 is 9503.509704369526\n",
      "Error for iteration 80 is 9503.506891389803\n",
      "Error for iteration 81 is 9503.504086585504\n",
      "Error for iteration 82 is 9503.500715676404\n",
      "Error for iteration 83 is 9503.497131534987\n",
      "Error for iteration 84 is 9503.493475604188\n",
      "Error for iteration 85 is 9503.489756456718\n",
      "Error for iteration 86 is 9503.485981811576\n",
      "Error for iteration 87 is 9503.481549617785\n",
      "Error for iteration 88 is 9503.476543156405\n",
      "Error for iteration 89 is 9503.471363619476\n",
      "Error for iteration 90 is 9503.466030783913\n",
      "Error for iteration 91 is 9503.460562470409\n",
      "Error for iteration 92 is 9503.454974733115\n",
      "Error for iteration 93 is 9503.449282031483\n",
      "Error for iteration 94 is 9503.443497385826\n",
      "Error for iteration 95 is 9503.437632518064\n",
      "Error for iteration 96 is 9503.431697978993\n",
      "Error for iteration 97 is 9503.42570326331\n",
      "Error for iteration 98 is 9503.41965691355\n",
      "Error for iteration 99 is 9503.413566613923\n",
      "Error for iteration 100 is 9503.407439275059\n",
      "Error for iteration 101 is 9503.401281110466\n",
      "Error for iteration 102 is 9503.395097705537\n",
      "Error for iteration 103 is 9503.388894079791\n",
      "Error for iteration 104 is 9503.382674742983\n",
      "Error for iteration 105 is 9503.376443745738\n",
      "Error for iteration 106 is 9503.370204725157\n",
      "Error for iteration 107 is 9503.363960945948\n",
      "Error for iteration 108 is 9503.357715337484\n",
      "Error for iteration 109 is 9503.351470527203\n",
      "Error for iteration 110 is 9503.345228870694\n",
      "Error for iteration 111 is 9503.338992478797\n",
      "Error for iteration 112 is 9503.332763242033\n",
      "Error for iteration 113 is 9503.32654285259\n",
      "Error for iteration 114 is 9503.320093186914\n",
      "Error for iteration 115 is 9503.31249117404\n",
      "Error for iteration 116 is 9503.30476743817\n",
      "Error for iteration 117 is 9503.29693797245\n",
      "Error for iteration 118 is 9503.28901717097\n",
      "Error for iteration 119 is 9503.281017985399\n",
      "Error for iteration 120 is 9503.272952066614\n",
      "Error for iteration 121 is 9503.264829892618\n",
      "Error for iteration 122 is 9503.256660884135\n",
      "Error for iteration 123 is 9503.248453508939\n",
      "Error for iteration 124 is 9503.240215376029\n",
      "Error for iteration 125 is 9503.231953320637\n",
      "Error for iteration 126 is 9503.223673480874\n",
      "Error for iteration 127 is 9503.215381366888\n",
      "Error for iteration 128 is 9503.20708192322\n",
      "Error for iteration 129 is 9503.198779585005\n",
      "Error for iteration 130 is 9503.190478328654\n",
      "Error for iteration 131 is 9503.182181717519\n",
      "Error for iteration 132 is 9503.173892943045\n",
      "Error for iteration 133 is 9503.165315779666\n",
      "Error for iteration 134 is 9503.155669587102\n",
      "Error for iteration 135 is 9503.145909786641\n",
      "Error for iteration 136 is 9503.13605288188\n",
      "Error for iteration 137 is 9503.1261137177\n",
      "Error for iteration 138 is 9503.116105643021\n",
      "Error for iteration 139 is 9503.106040657876\n",
      "Error for iteration 140 is 9503.095929546309\n",
      "Error for iteration 141 is 9503.08578199632\n",
      "Error for iteration 142 is 9503.075606708202\n",
      "Error for iteration 143 is 9503.065411492264\n",
      "Error for iteration 144 is 9503.05520335701\n",
      "Error for iteration 145 is 9503.044988588692\n",
      "Error for iteration 146 is 9503.03472380991\n",
      "Error for iteration 147 is 9503.02353828734\n",
      "Error for iteration 148 is 9503.012271952637\n",
      "Error for iteration 149 is 9503.000938853844\n",
      "Error for iteration 150 is 9502.989551615214\n",
      "Error for iteration 151 is 9502.976725773742\n",
      "Error for iteration 152 is 9502.96350736775\n",
      "Error for iteration 153 is 9502.950094289146\n",
      "Error for iteration 154 is 9502.936514135288\n",
      "Error for iteration 155 is 9502.922791735242\n",
      "Error for iteration 156 is 9502.908949419843\n",
      "Error for iteration 157 is 9502.895007266077\n",
      "Error for iteration 158 is 9502.880983318046\n",
      "Error for iteration 159 is 9502.866893786724\n",
      "Error for iteration 160 is 9502.852753230447\n",
      "Error for iteration 161 is 9502.838574717893\n",
      "Error for iteration 162 is 9502.824372878453\n",
      "Error for iteration 163 is 9502.81019112721\n",
      "Error for iteration 164 is 9502.79600582691\n",
      "Error for iteration 165 is 9502.781825082038\n",
      "Error for iteration 166 is 9502.767656147249\n",
      "Error for iteration 167 is 9502.753505511913\n",
      "Error for iteration 168 is 9502.73937897632\n",
      "Error for iteration 169 is 9502.725281720393\n",
      "Error for iteration 170 is 9502.71121836559\n",
      "Error for iteration 171 is 9502.697193030685\n",
      "Error for iteration 172 is 9502.682340725356\n",
      "Error for iteration 173 is 9502.666609237054\n",
      "Error for iteration 174 is 9502.650769069432\n",
      "Error for iteration 175 is 9502.63484082246\n",
      "Error for iteration 176 is 9502.618911057674\n",
      "Error for iteration 177 is 9502.602963021714\n",
      "Error for iteration 178 is 9502.586984553498\n",
      "Error for iteration 179 is 9502.570988062147\n",
      "Error for iteration 180 is 9502.554984668332\n",
      "Error for iteration 181 is 9502.53898433203\n",
      "Error for iteration 182 is 9502.52299596776\n",
      "Error for iteration 183 is 9502.5070275485\n",
      "Error for iteration 184 is 9502.49108619941\n",
      "Error for iteration 185 is 9502.475178282304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for iteration 186 is 9502.459309471782\n",
      "Error for iteration 187 is 9502.443484823876\n",
      "Error for iteration 188 is 9502.427708848854\n",
      "Error for iteration 189 is 9502.411988507336\n",
      "Error for iteration 190 is 9502.396330134927\n",
      "Error for iteration 191 is 9502.380737312444\n",
      "Error for iteration 192 is 9502.365213199468\n",
      "Error for iteration 193 is 9502.349760576708\n",
      "Error for iteration 194 is 9502.334381884168\n",
      "Error for iteration 195 is 9502.31772599215\n",
      "Error for iteration 196 is 9502.300155963121\n",
      "Error for iteration 197 is 9502.282463530262\n",
      "Error for iteration 198 is 9502.264674096477\n",
      "Error for iteration 199 is 9502.24681046185\n",
      "Error for iteration 200 is 9502.228893078487\n",
      "Error for iteration 201 is 9502.210940281042\n",
      "Error for iteration 202 is 9502.192968495048\n",
      "Error for iteration 203 is 9502.174992425213\n",
      "Error for iteration 204 is 9502.155902958364\n",
      "Error for iteration 205 is 9502.135964258583\n",
      "Error for iteration 206 is 9502.11587553844\n",
      "Error for iteration 207 is 9502.095670929813\n",
      "Error for iteration 208 is 9502.075380396465\n",
      "Error for iteration 209 is 9502.055029328027\n",
      "Error for iteration 210 is 9502.034640470565\n",
      "Error for iteration 211 is 9502.014234185905\n",
      "Error for iteration 212 is 9501.993828686127\n",
      "Error for iteration 213 is 9501.973440245532\n",
      "Error for iteration 214 is 9501.95308339218\n",
      "Error for iteration 215 is 9501.932771080852\n",
      "Error for iteration 216 is 9501.912514849242\n",
      "Error for iteration 217 is 9501.89232495889\n",
      "Error for iteration 218 is 9501.872210522408\n",
      "Error for iteration 219 is 9501.852179618192\n",
      "Error for iteration 220 is 9501.832239393909\n",
      "Error for iteration 221 is 9501.812396159803\n",
      "Error for iteration 222 is 9501.792655472822\n",
      "Error for iteration 223 is 9501.773022212408\n",
      "Error for iteration 224 is 9501.753500648854\n",
      "Error for iteration 225 is 9501.734094504849\n",
      "Error for iteration 226 is 9501.712999836394\n",
      "Error for iteration 227 is 9501.689406584448\n",
      "Error for iteration 228 is 9501.665535844486\n",
      "Error for iteration 229 is 9501.641438239043\n",
      "Error for iteration 230 is 9501.617160540405\n",
      "Error for iteration 231 is 9501.592746329361\n",
      "Error for iteration 232 is 9501.568232711066\n",
      "Error for iteration 233 is 9501.543652879225\n",
      "Error for iteration 234 is 9501.519036541245\n",
      "Error for iteration 235 is 9501.494410259122\n",
      "Error for iteration 236 is 9501.469797758022\n",
      "Error for iteration 237 is 9501.445220205454\n",
      "Error for iteration 238 is 9501.420696463687\n",
      "Error for iteration 239 is 9501.396243317911\n",
      "Error for iteration 240 is 9501.371875682336\n",
      "Error for iteration 241 is 9501.347182391117\n",
      "Error for iteration 242 is 9501.32056268752\n",
      "Error for iteration 243 is 9501.293852451685\n",
      "Error for iteration 244 is 9501.267087102751\n",
      "Error for iteration 245 is 9501.240298315231\n",
      "Error for iteration 246 is 9501.21351438527\n",
      "Error for iteration 247 is 9501.186760562212\n",
      "Error for iteration 248 is 9501.160059348615\n",
      "Error for iteration 249 is 9501.132750509889\n",
      "Error for iteration 250 is 9501.102950850658\n",
      "Error for iteration 251 is 9501.072956981257\n",
      "Error for iteration 252 is 9501.042508844352\n",
      "Error for iteration 253 is 9501.009629698736\n",
      "Error for iteration 254 is 9500.976451500266\n",
      "Error for iteration 255 is 9500.943042272947\n",
      "Error for iteration 256 is 9500.909468247692\n",
      "Error for iteration 257 is 9500.875786617828\n",
      "Error for iteration 258 is 9500.842046864913\n",
      "Error for iteration 259 is 9500.808293179089\n",
      "Error for iteration 260 is 9500.77456497396\n",
      "Error for iteration 261 is 9500.740897353446\n",
      "Error for iteration 262 is 9500.70732153477\n",
      "Error for iteration 263 is 9500.673865231478\n",
      "Error for iteration 264 is 9500.640552999988\n",
      "Error for iteration 265 is 9500.60740655306\n",
      "Error for iteration 266 is 9500.571978266962\n",
      "Error for iteration 267 is 9500.53568087902\n",
      "Error for iteration 268 is 9500.499306520122\n",
      "Error for iteration 269 is 9500.462906917226\n",
      "Error for iteration 270 is 9500.425918355853\n",
      "Error for iteration 271 is 9500.386823699655\n",
      "Error for iteration 272 is 9500.347579553305\n",
      "Error for iteration 273 is 9500.308250545448\n",
      "Error for iteration 274 is 9500.26889437649\n",
      "Error for iteration 275 is 9500.228486546042\n",
      "Error for iteration 276 is 9500.186829405058\n",
      "Error for iteration 277 is 9500.145071284689\n",
      "Error for iteration 278 is 9500.103294754888\n",
      "Error for iteration 279 is 9500.061571040598\n",
      "Error for iteration 280 is 9500.019954144229\n",
      "Error for iteration 281 is 9499.978490185584\n",
      "Error for iteration 282 is 9499.937221842722\n",
      "Error for iteration 283 is 9499.896186477632\n",
      "Error for iteration 284 is 9499.853405566031\n",
      "Error for iteration 285 is 9499.809721998587\n",
      "Error for iteration 286 is 9499.7660972743\n",
      "Error for iteration 287 is 9499.722589055546\n",
      "Error for iteration 288 is 9499.678593747987\n",
      "Error for iteration 289 is 9499.631664780407\n",
      "Error for iteration 290 is 9499.58372197659\n",
      "Error for iteration 291 is 9499.533350346248\n",
      "Error for iteration 292 is 9499.482779145548\n",
      "Error for iteration 293 is 9499.430320986763\n",
      "Error for iteration 294 is 9499.375908641377\n",
      "Error for iteration 295 is 9499.319266476656\n",
      "Error for iteration 296 is 9499.258398453414\n",
      "Error for iteration 297 is 9499.192064977231\n",
      "Error for iteration 298 is 9499.124785581203\n",
      "Error for iteration 299 is 9499.056794059421\n",
      "After 300 iterations, the total error is 9499.056794059421\n",
      "The final weight vectors are (starting from input to output layers) \n",
      "[[-0.01832119 -0.19688525  0.53418992  0.61235562  0.56386517  0.12063244\n",
      "   0.47245189 -0.79271046  0.21532229]\n",
      " [ 0.22120716 -0.90950323  0.97278656  0.43940381 -0.90057683 -0.66146931\n",
      "   0.71278743 -0.97973514  0.962908  ]\n",
      " [ 0.37741011 -0.94184842 -0.61180257  0.66293676  0.39916593  0.49769073\n",
      "   0.20185788 -0.50891926  0.04001505]\n",
      " [ 0.27436864 -0.03472821 -0.56599747  0.96115889  0.35830954 -0.97575152\n",
      "   0.17329622  0.92339198 -0.02381749]\n",
      " [ 0.37531995  0.74908805  0.97137908  1.00119603 -0.88314591 -0.47932434\n",
      "  -0.3824285  -0.1344892  -0.16652667]\n",
      " [ 0.15817671  0.84587106  0.91919741 -0.50624983 -0.96276039 -0.79637263\n",
      "   0.71358923 -0.49343588  0.70249241]\n",
      " [-0.85519933  0.49858276 -0.79271462 -0.26901012  0.13200995  0.76634683\n",
      "   0.91550294 -0.68597685 -0.82554709]\n",
      " [-0.40886046  0.34381526  0.65709047  0.2853228  -0.79940352  0.18167675\n",
      "   0.51254298  0.19012205  0.04521356]\n",
      " [-0.80257543 -0.40646979 -0.57049661  0.40585721 -0.962585    0.10456913\n",
      "   0.08347906 -0.81010515 -0.15827155]\n",
      " [-0.13717443  0.88991364  0.61775103  0.01297024  0.13948257  0.63666362\n",
      "  -0.22678671  0.73079961 -0.28612021]\n",
      " [ 0.96161251 -0.01100838  0.36452084  0.98137843 -0.02174177  0.6154395\n",
      "   0.35118215 -0.49319159  0.27630561]\n",
      " [-0.26460964  0.51713512  0.31361439 -0.67358125  0.6839746  -0.16567347\n",
      "   0.20843885 -0.37064018 -0.63077773]\n",
      " [-0.52516976 -0.08748427 -0.50824735  0.0218491   0.56910305  0.63764198\n",
      "   0.59985205 -0.09632448 -0.24824643]\n",
      " [-0.9859319   0.70671444 -0.44851329 -0.0761347   0.05718004 -0.91087842\n",
      "   0.02270122  0.40287388  0.08520996]\n",
      " [ 0.65989048 -0.2770169   0.65963599 -0.33070289 -0.74154724 -0.98002323\n",
      "   0.10720327 -0.69343255  0.27260906]\n",
      " [-0.29233129  0.59387602 -0.47189322 -0.80425492  0.81511254  0.74156027\n",
      "   0.81873764  0.00558208  0.11859588]\n",
      " [ 0.94972603 -0.30897139  0.04058924  0.47568232  0.26490066  0.31789389\n",
      "  -0.79643801 -0.54920786 -0.83368832]\n",
      " [ 0.68511578 -0.6753767   0.68576097 -0.90858452 -0.55507383  0.30392546\n",
      "  -0.91288999  0.3970434   0.83173867]\n",
      " [ 0.68955421  0.22171869 -0.32827587  0.25831573  0.20951995  0.62524015\n",
      "   0.47266533 -0.56778352  0.38397956]\n",
      " [-0.0339944   0.58444277  0.45859682 -0.41948318  0.73877298 -0.37616892\n",
      "   0.95992331  0.38403525  0.848086  ]]\n",
      "The final weight vectors are (starting from input to output layers) \n",
      "[[-0.93959682 -0.92555112 -0.28806853 -0.09361392  0.62397504 -0.48015863\n",
      "  -0.34293354  0.89010057 -0.0629782   0.63875015 -0.00491228  0.5236165\n",
      "  -0.91126741  0.20061663 -0.47892079 -0.78370672 -0.53627207 -0.98735831\n",
      "  -0.8672263  -0.31212619]]\n",
      "The final bias vectors are (starting from input to output layers) \n",
      "[[ 0.58618445]\n",
      " [ 0.32730287]\n",
      " [-0.33707971]\n",
      " [ 0.80883694]\n",
      " [ 0.45229071]\n",
      " [ 0.32072136]\n",
      " [ 0.89133957]\n",
      " [-0.19564703]\n",
      " [-0.08449265]\n",
      " [-0.19306489]\n",
      " [ 0.08424371]\n",
      " [ 0.04756394]\n",
      " [-0.48226036]\n",
      " [ 0.10998507]\n",
      " [ 0.54457783]\n",
      " [ 0.23297148]\n",
      " [-0.36097668]\n",
      " [-0.99646036]\n",
      " [-0.13992388]\n",
      " [ 0.70445439]]\n",
      "The final bias vectors are (starting from input to output layers) \n",
      "[[1.0229327]]\n"
     ]
    }
   ],
   "source": [
    "nn_model = NeuralNet(X_train.iloc[:,0:9].T,y_train.T, h=20)\n",
    "nn_model.train(activation=\"relu\")\n",
    "\n",
    "\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside predict\n",
      "Error on Test Dataset is 4544.888536219123\n"
     ]
    }
   ],
   "source": [
    "predictions = nn_model.predict(X_test.iloc[:,0:9].T,y_test.T,activation=\"tanh\")\n",
    "predictions = np.around(predictions, 0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
