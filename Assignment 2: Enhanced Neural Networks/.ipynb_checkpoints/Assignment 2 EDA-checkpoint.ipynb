{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Neural Network (One Hidden Layer) with Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> <b> <u> Dataset background:</u></b> </h2>\n",
    "<ul>\n",
    "    <li>Data: Diabetic Encounters (1-14 days/each) from 130 Hospitals for 10 years (1999-2008) </li>\n",
    "    <li>Goal: Predict if a diabetic patient will be readmitted to a hospital (less than 30 days, after 30 days, or never)</li>\n",
    "    <li>Target Feature: readmitted </li>\n",
    "    <li> <a href = \"https://archive.ics.uci.edu/ml/datasets/Diabetes+130-US+hospitals+for+years+1999-2008\">Dataset Source</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import all required libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#display all columns of dataframe\n",
    "pd.pandas.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dataset Shape: (101766, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_nbr</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>payer_code</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>diag_2</th>\n",
       "      <th>diag_3</th>\n",
       "      <th>number_diagnoses</th>\n",
       "      <th>max_glu_serum</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>metformin</th>\n",
       "      <th>repaglinide</th>\n",
       "      <th>nateglinide</th>\n",
       "      <th>chlorpropamide</th>\n",
       "      <th>glimepiride</th>\n",
       "      <th>acetohexamide</th>\n",
       "      <th>glipizide</th>\n",
       "      <th>glyburide</th>\n",
       "      <th>tolbutamide</th>\n",
       "      <th>pioglitazone</th>\n",
       "      <th>rosiglitazone</th>\n",
       "      <th>acarbose</th>\n",
       "      <th>miglitol</th>\n",
       "      <th>troglitazone</th>\n",
       "      <th>tolazamide</th>\n",
       "      <th>examide</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>11522</td>\n",
       "      <td>47603976</td>\n",
       "      <td>53229249</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>InternalMedicine</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>332</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26691</td>\n",
       "      <td>87798972</td>\n",
       "      <td>27645615</td>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>?</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>CP</td>\n",
       "      <td>Family/GeneralPractice</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.2</td>\n",
       "      <td>530</td>\n",
       "      <td>278</td>\n",
       "      <td>3</td>\n",
       "      <td>&gt;300</td>\n",
       "      <td>None</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Down</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50457</td>\n",
       "      <td>151582878</td>\n",
       "      <td>99473202</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[70-80)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>CM</td>\n",
       "      <td>?</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>805</td>\n",
       "      <td>250</td>\n",
       "      <td>E884</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4889</td>\n",
       "      <td>26569620</td>\n",
       "      <td>17707707</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>?</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>?</td>\n",
       "      <td>Family/GeneralPractice</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>428</td>\n",
       "      <td>518</td>\n",
       "      <td>585</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2959</td>\n",
       "      <td>18860946</td>\n",
       "      <td>53593200</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[80-90)</td>\n",
       "      <td>[50-75)</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "      <td>427</td>\n",
       "      <td>593</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&lt;30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       encounter_id  patient_nbr             race gender      age   weight  \\\n",
       "11522      47603976     53229249        Caucasian   Male  [70-80)        ?   \n",
       "26691      87798972     27645615  AfricanAmerican   Male  [40-50)        ?   \n",
       "50457     151582878     99473202            Asian   Male  [70-80)        ?   \n",
       "4889       26569620     17707707        Caucasian   Male  [80-90)        ?   \n",
       "2959       18860946     53593200        Caucasian   Male  [80-90)  [50-75)   \n",
       "\n",
       "       admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "11522                  1                         1                    7   \n",
       "26691                  5                         1                   17   \n",
       "50457                  1                         6                    7   \n",
       "4889                   1                        11                    7   \n",
       "2959                   6                         3                   17   \n",
       "\n",
       "       time_in_hospital payer_code       medical_specialty  \\\n",
       "11522                 2          ?        InternalMedicine   \n",
       "26691                 1         CP  Family/GeneralPractice   \n",
       "50457                 5         CM                       ?   \n",
       "4889                  9          ?  Family/GeneralPractice   \n",
       "2959                 10          ?                       ?   \n",
       "\n",
       "       num_lab_procedures  num_procedures  num_medications  number_outpatient  \\\n",
       "11522                  48               0               10                  0   \n",
       "26691                  18               0               12                  0   \n",
       "50457                  51               0                1                  0   \n",
       "4889                   67               6               26                  0   \n",
       "2959                   48               1               20                  0   \n",
       "\n",
       "       number_emergency  number_inpatient diag_1 diag_2 diag_3  \\\n",
       "11522                 0                 1    780    780    332   \n",
       "26691                 0                 0  250.2    530    278   \n",
       "50457                 0                 0    805    250   E884   \n",
       "4889                  0                 1    428    518    585   \n",
       "2959                  0                 0    507    427    593   \n",
       "\n",
       "       number_diagnoses max_glu_serum A1Cresult metformin repaglinide  \\\n",
       "11522                 8          None      None        No          No   \n",
       "26691                 3          >300      None    Steady          No   \n",
       "50457                 4          None      None        No          No   \n",
       "4889                  9          None      None        No          No   \n",
       "2959                  7          None      None        No          No   \n",
       "\n",
       "      nateglinide chlorpropamide glimepiride acetohexamide glipizide  \\\n",
       "11522          No             No          No            No        No   \n",
       "26691          No             No          No            No        No   \n",
       "50457          No             No          No            No        No   \n",
       "4889           No             No          No            No        No   \n",
       "2959           No             No          No            No        No   \n",
       "\n",
       "      glyburide tolbutamide pioglitazone rosiglitazone acarbose miglitol  \\\n",
       "11522        No          No           No            No       No       No   \n",
       "26691        No          No           No            No       No       No   \n",
       "50457        No          No           No            No       No       No   \n",
       "4889         No          No           No            No       No       No   \n",
       "2959         No          No           No            No       No       No   \n",
       "\n",
       "      troglitazone tolazamide examide citoglipton insulin glyburide-metformin  \\\n",
       "11522           No         No      No          No      No                  No   \n",
       "26691           No         No      No          No    Down                  No   \n",
       "50457           No         No      No          No      No                  No   \n",
       "4889            No         No      No          No      No                  No   \n",
       "2959            No         No      No          No  Steady                  No   \n",
       "\n",
       "      glipizide-metformin glimepiride-pioglitazone metformin-rosiglitazone  \\\n",
       "11522                  No                       No                      No   \n",
       "26691                  No                       No                      No   \n",
       "50457                  No                       No                      No   \n",
       "4889                   No                       No                      No   \n",
       "2959                   No                       No                      No   \n",
       "\n",
       "      metformin-pioglitazone change diabetesMed readmitted  \n",
       "11522                     No     No          No        >30  \n",
       "26691                     No     Ch         Yes         NO  \n",
       "50457                     No     No          No         NO  \n",
       "4889                      No     No          No         NO  \n",
       "2959                      No     No         Yes        <30  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset \n",
    "dataset_url = \"https://raw.githubusercontent.com/ronakHegde98/CS-4372-Computational-Methods-for-Data-Scientists/master/data/diabetic_data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "\n",
    "print(f\"Initial Dataset Shape: {df.shape}\")\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16773 patients with multiple records\n"
     ]
    }
   ],
   "source": [
    "## check if patients have multiple records\n",
    "print(f\"There are {np.sum(df['patient_nbr'].value_counts() > 1)} patients with multiple records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 37 categorical columns and 13 numerical columns\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = [col for col in df.columns if df[col].dtype == np.dtype(np.object)]\n",
    "print(f\"There are {len(categorical_cols)} categorical columns and {len(df.columns)-len(categorical_cols)} numerical columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Handling Missing Values </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 192849 '?' values in our dataset which is approx 3.79% of our entire dataset\n"
     ]
    }
   ],
   "source": [
    "## sum all missing values for each row of df (axis 0 is row)\n",
    "missing_count = np.sum(np.sum(np.equal(df, '?'), axis=0))\n",
    "print(f\"There are {missing_count} '?' values in our dataset which is approx {np.round((missing_count/(np.multiply(df.shape[0], df.shape[1])))*100,2)}% of our entire dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert ?'s into np.nan\n",
    "df.replace(\"?\", np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing data\n",
      " race: 2273\n",
      " weight: 98569\n",
      " payer_code: 40256\n",
      " medical_specialty: 49949\n",
      " diag_1: 21\n",
      " diag_2: 358\n",
      " diag_3: 1423\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns with missing data\")\n",
    "missing_cols = df.columns[df.isnull().any()].tolist()\n",
    "for col in missing_cols:\n",
    "    print(' ' + col + ': ' + str(df[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop rows where gender is Unknown/Invalid\n",
    "df.drop(df[df['gender'] == \"Unknown/Invalid\"].index, axis=0, inplace=True)\n",
    "\n",
    "## dropping columns that have many missing values\n",
    "dropped_columns = ['weight', 'payer_code', 'medical_specialty']\n",
    "dropped_columns.append(\"encounter_id\")\n",
    "dropped_columns.append('discharge_disposition_id')\n",
    "\n",
    "## dropping columns that have little to no variability\n",
    "for col in categorical_cols:\n",
    "    if(df[col].value_counts(normalize=True).max() > 0.948):\n",
    "        dropped_columns.append(col)\n",
    "        \n",
    "df.drop(columns=dropped_columns, axis=1, inplace=True)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Some Patients have multiple records </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## one record per patient (where they had max of time_in_hospital)\n",
    "df = df.loc[df.groupby(\"patient_nbr\", sort=False)['time_in_hospital'].idxmax()]\n",
    "df.drop(columns = ['patient_nbr'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## convert our categorical variable (if readmitted -> 1 else 0)\n",
    "df['readmitted'] = np.where(df['readmitted']!='NO',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert age ranges to the midpoint of the ranges\n",
    "new_ages = {\n",
    "    \"[0-10)\": 5,\n",
    "    \"[10-20)\": 15,\n",
    "    \"[20-30)\": 25,\n",
    "    \"[30-40)\": 35,\n",
    "    \"[40-50)\": 45,\n",
    "    \"[50-60)\": 55,\n",
    "    \"[60-70)\": 65,\n",
    "    \"[70-80)\": 75,\n",
    "    \"[80-90)\": 85,\n",
    "    \"[90-100)\": 95\n",
    "}\n",
    "\n",
    "df['age'] = df['age'].map(new_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_glu_serums = {\n",
    "    \"None\": 0,\n",
    "    \"Norm\": 100,\n",
    "    \">200\": 200,\n",
    "    \">300\": 300\n",
    "}\n",
    "df['max_glu_serum'] = df['max_glu_serum'].map(max_glu_serums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1CResult_map = {\n",
    "    \"None\": 0,\n",
    "    \"Norm\": 5,\n",
    "    \">7\": 7,\n",
    "    \">8\": 8\n",
    "}\n",
    "df['A1Cresult'] = df['A1Cresult'].map(A1CResult_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting binary variables into -1 or 1\n",
    "df['change'] = np.where(df['change']=='No',-1,1)\n",
    "df['diabetesMed'] = np.where(df['diabetesMed']=='No',-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_codes = {\n",
    "    \"No\": -20,\n",
    "    \"Down\": -10, \n",
    "    \"Steady\": 0,\n",
    "    \"Up\": 10    \n",
    "}\n",
    "drugs = ['metformin','glipizide','glyburide', 'pioglitazone', 'rosiglitazone','insulin'] \n",
    "for drug in drugs:\n",
    "    df[drug] = df[drug].map(drug_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## mapping diagnosis categories according to paper (else 800 plus features)\n",
    "diagnosis_cols = ['diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "for col in diagnosis_cols:\n",
    "    df['tmp'] = np.nan\n",
    "    df.loc[(df[col].str.contains(\"250\")), col] = '250'\n",
    "    df.loc[(df[col].str.startswith('V')) | (df[col].str.startswith('E')), col] = '-999' \n",
    "\n",
    "    df[col] = df[col].astype(float)\n",
    "    \n",
    "    #convert the correct ranges based on values given in paper\n",
    "    df.loc[(((df[col] >=390) & (df[col]<=460)) | (df[col] == 785)), 'tmp'] = 'Circulatory'\n",
    "    df.loc[(((df[col] >=460) & (df[col]<=519)) | (df[col] == 786)), 'tmp'] = 'Respiratory'\n",
    "    df.loc[(((df[col] >=520) & (df[col]<=579)) | (df[col] == 787)), 'tmp'] = 'Digestive'\n",
    "    df.loc[(((df[col] >=580) & (df[col]<=629)) | (df[col] == 788)), 'tmp'] = 'Genitourinary'\n",
    "    df.loc[((df[col] >=800) & (df[col]<=999)), 'tmp'] = 'Injury'\n",
    "    df.loc[((df[col] >=710) & (df[col]<=739)), 'tmp'] = 'Musculoskeletal'\n",
    "    df.loc[((df[col] >=140) & (df[col]<=239)), 'tmp'] = 'Neoplasms'\n",
    "    df.loc[(df[col] == 250), 'tmp'] = 'Diabetes'\n",
    "    \n",
    "    df['tmp'].fillna(value = \"Other\", inplace=True)\n",
    "    \n",
    "    df[col] = df['tmp']\n",
    "    df.drop(columns=['tmp'], inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## admission_source_id\n",
    "df['tmp'] = np.nan\n",
    "col = 'admission_source_id'\n",
    "df.loc[((df[col].between(4,6)) | (df[col] == 10) | (df[col] == 18) | (df[col] == 22) | (df[col].between(25,26))), 'tmp'] = \"Transfer_Source\"\n",
    "df.loc[df[col].between(1,3), 'tmp'] = \"Referral_Source\"\n",
    "df.loc[((df[col].between(11,14))| (df[col].between(23,24))), 'tmp'] = \"Birth_Source\"\n",
    "df.loc[df[col] == 7, 'tmp'] = \"Emergency_Source\"\n",
    "df.loc[((df[col] == 8) | (df[col]==19)), 'tmp'] = \"Other\"\n",
    "        \n",
    "df['tmp'].fillna(value = \"Unknown\", inplace=True)\n",
    "df[col] = df['tmp']\n",
    "df.drop(columns=['tmp'], inplace=True)\n",
    "\n",
    "\n",
    "##mapping admission type_id\n",
    "df['tmp'] = np.nan\n",
    "col = 'admission_type_id'\n",
    "df.loc[df[col] == 1, 'tmp'] = 'Emergency_Type'\n",
    "df.loc[df[col] == 2, 'tmp'] = 'Urgent_Type'\n",
    "df.loc[df[col] == 3, 'tmp'] = 'Elective_Type'\n",
    "df.loc[df[col] == 7, 'tmp'] = 'Trauma_Type'\n",
    "df.loc[df[col] == 4, 'tmp'] = 'Newborn_Type'\n",
    "\n",
    "df['tmp'].fillna(value = \"Unknown\", inplace=True)\n",
    "df[col] = df['tmp']\n",
    "df.drop(columns=['tmp'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoder(df, cols):\n",
    "    \"\"\"one-hot encoding function for all our categorical columns\"\"\"\n",
    "    \n",
    "    for col in cols:\n",
    "        if(\"admission\" in col):\n",
    "            dummies = pd.get_dummies(df[col], drop_first=False)\n",
    "        else:\n",
    "            dummies = pd.get_dummies(df[col], prefix=col, drop_first=False)\n",
    "        df = pd.concat([df, dummies], axis=1)   \n",
    "        df.drop([col],axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot encoding \n",
    "categorical_columns = [col for col in df.columns if df[col].dtype == np.dtype(object)]\n",
    "df = one_hot_encoder(df, categorical_columns)\n",
    "df.columns = map(str.lower, df.columns)\n",
    "\n",
    "#train-test-split\n",
    "target_variable = 'readmitted'\n",
    "Y_feature = df[target_variable]\n",
    "X_features = df.drop(columns=[target_variable])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features,Y_feature, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize of numerical columns\n",
    "mm_scaler = MinMaxScaler()\n",
    "X_train = pd.DataFrame(mm_scaler.fit_transform(X_train), columns = X_train.columns) \n",
    "X_test = pd.DataFrame(mm_scaler.fit_transform(X_test), columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "\n",
    "    def __init__(self, X_train, y_train, h=4):\n",
    "        #np.random.seed(1)\n",
    "        # h represents the number of neurons in the hidden layers\n",
    "        self.X = X_train\n",
    "        self.y = y_train\n",
    "\n",
    "        # Find number of input and output layers from the dataset\n",
    "        input_layer_size = self.X.shape[1]\n",
    "        \n",
    "        self.output_layer_size = 1\n",
    "\n",
    "        # assign random weights to matrices in network\n",
    "        # number of weights connecting layers = (no. of nodes in previous layer) x (no. of nodes in following layer)\n",
    "        self.W_hidden = 2 * np.random.random((input_layer_size, h)) - 1\n",
    "        self.Wb_hidden = 2 * np.random.random((1, h)) - 1\n",
    "\n",
    "        self.W_output = 2 * np.random.random((h, self.output_layer_size)) - 1\n",
    "        self.Wb_output = np.ones((1, self.output_layer_size))\n",
    "\n",
    "        self.deltaOut = np.zeros((self.output_layer_size, 1))\n",
    "        self.deltaHidden = np.zeros((h, 1))\n",
    "        self.h = h\n",
    "\n",
    "\n",
    "    def __activation(self, x, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            self.__sigmoid(self, x)\n",
    "        elif activation == \"tanh\":\n",
    "            self.__tanh(self,x)\n",
    "        elif activation == \"relu\":\n",
    "            self.__relu(self,x)\n",
    "     \n",
    "\n",
    "    def __activation_derivative(self, x, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            self.__sigmoid_derivative(self, x)\n",
    "        elif activation == \"tanh\":\n",
    "            self.__tanh_derivative(self,x)\n",
    "        elif activation == \"relu\":\n",
    "            self.__relu_derivative(self,x)\n",
    "\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def __tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def __relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def __tanh_derivative(self, x):\n",
    "        return 1-(np.tanh(x))**2\n",
    "    \n",
    "    def __relu_derivative(self,x):\n",
    "        return (x>0)*1\n",
    "\n",
    "\n",
    "    # Below is the training function\n",
    "\n",
    "    def train(self, activation, max_iterations=2, learning_rate=0.01):\n",
    "        for iteration in range(max_iterations):\n",
    "            out = self.forward_pass(activation)\n",
    "            \n",
    "            error = 0.5 * np.power((out - self.y), 2)\n",
    "            # TODO: I have coded the sigmoid activation, you have to do the rest\n",
    "            self.backward_pass(out, activation)\n",
    "            \n",
    "            print(self.deltaOut)\n",
    "#             print(self.deltaHidden)\n",
    "            break\n",
    "            update_weight_output = learning_rate * np.dot(self.X_hidden.T, self.deltaOut)\n",
    "            update_weight_output_b = learning_rate * np.dot(np.ones((np.size(self.X, 0), 1)).T, self.deltaOut)\n",
    "\n",
    "            update_weight_hidden = learning_rate * np.dot(self.X.T, self.deltaHidden)\n",
    "            update_weight_hidden_b = learning_rate * np.dot(np.ones((np.size(self.X, 0), 1)).T, self.deltaHidden)\n",
    "\n",
    "            self.W_output += update_weight_output\n",
    "            self.Wb_output += update_weight_output_b\n",
    "            self.W_hidden += update_weight_hidden\n",
    "            self.Wb_hidden += update_weight_hidden_b\n",
    "            \n",
    "#             print(self.Wb_hidden)\n",
    "            \n",
    "            print(f\"Error for iteration {iteration} is {np.sum(error)}\")\n",
    "#         print(\"After \" + str(max_iterations) + \" iterations, the total error is \" + str(np.sum(error)))\n",
    "#         print(\"The final weight vectors are (starting from input to output layers) \\n\" + str(self.W_hidden))\n",
    "#         print(\"The final weight vectors are (starting from input to output layers) \\n\" + str(self.W_output))\n",
    "\n",
    "#         print(\"The final bias vectors are (starting from input to output layers) \\n\" + str(self.Wb_hidden))\n",
    "#         print(\"The final bias vectors are (starting from input to output layers) \\n\" + str(self.Wb_output))\n",
    "\n",
    "    def forward_pass(self, activation):\n",
    "        # pass our inputs through our neural network\n",
    "        in_hidden = np.dot(self.X, self.W_hidden) + self.Wb_hidden\n",
    "\n",
    "        # TODO: I have coded the sigmoid activation, you have to do the rest\n",
    "        if activation == \"sigmoid\":\n",
    "            self.X_hidden = self.__sigmoid(in_hidden)\n",
    "        elif activation == \"tanh\":\n",
    "            self.X_hidden = self.__tanh(in_hidden)\n",
    "        elif activation == \"relu\":\n",
    "            self.X_hidden = self.__relu(in_hidden)\n",
    "\n",
    "        in_output = np.dot(self.X_hidden, self.W_output) + self.Wb_output\n",
    "\n",
    "        # output \n",
    "        if activation == \"sigmoid\":\n",
    "            out = self.__sigmoid(in_output)\n",
    "        elif activation == \"tanh\":\n",
    "            out = self.__tanh(in_output)\n",
    "        elif activation == \"relu\":\n",
    "            out = self.__relu(in_output)\n",
    "        return out\n",
    "\n",
    "    def backward_pass(self, out, activation):\n",
    "        # pass our inputs through our neural network\n",
    "        self.compute_output_delta(out, activation)\n",
    "        self.compute_hidden_delta(activation)\n",
    "        print(self.deltaHidden)\n",
    "        \n",
    "\n",
    "    # TODO: Implement other activation functions\n",
    "\n",
    "    def compute_output_delta(self, out, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            delta_output = (self.y - out) * (self.__sigmoid_derivative(out))\n",
    "        elif activation == \"tanh\":\n",
    "            delta_output = (self.y - out) * (self.__tanh_derivative(out))\n",
    "        elif activation == \"relu\":\n",
    "            delta_output = (self.y - out) * (self.__relu_derivative(out))\n",
    "\n",
    "        self.deltaOut = delta_output\n",
    "\n",
    "    def compute_hidden_delta(self, activation):\n",
    "        if activation == \"sigmoid\":\n",
    "            delta_hidden_layer = (self.deltaOut.dot(self.W_output.T)) * (self.__sigmoid_derivative(self.X_hidden))\n",
    "        elif activation == \"tanh\":\n",
    "            delta_hidden_layer = (self.deltaOut.dot(self.W_output.T)) * (self.__tanh_derivative(self.X_hidden))\n",
    "        elif activation == \"relu\":\n",
    "            delta_hidden_layer = (self.deltaOut.dot(self.W_output.T)) * (self.__relu_derivative(self.X_hidden))\n",
    "            \n",
    "        self.deltaHidden = delta_hidden_layer\n",
    "\n",
    "    # TODO: Implement the predict function for applying the trained model on the  test dataset.\n",
    "    # You can assume that the test dataset has the same format as the training dataset\n",
    "    # You have to output the test error from this function\n",
    "\n",
    "    def predict(self, X_test, y_test):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -0.         -0.34431661 ... -0.31159388  0.\n",
      "   0.30443981]\n",
      " [-0.          0.          0.07088055 ...  0.         -0.02074915\n",
      "  -0.06267157]\n",
      " [-0.          0.          0.         ...  0.41093099 -0.\n",
      "  -0.40149618]\n",
      " ...\n",
      " [-0.          0.          0.         ...  1.24105232 -0.\n",
      "  -1.21255826]\n",
      " [-0.          0.          1.49394449 ...  0.         -0.43732833\n",
      "  -1.32092432]\n",
      " [-0.75262946  0.          1.28906129 ...  1.1665531  -0.\n",
      "  -1.13976952]]\n",
      "[[ 0.37983413]\n",
      " [-0.07819214]\n",
      " [-0.50092645]\n",
      " ...\n",
      " [-1.51284754]\n",
      " [-1.64805038]\n",
      " [-1.42203272]]\n",
      "[[ 0.         -0.         -0.34431661 ... -0.31159388  0.\n",
      "   0.30443981]\n",
      " [-0.          0.          0.07088055 ...  0.         -0.02074915\n",
      "  -0.06267157]\n",
      " [-0.          0.          0.         ...  0.41093099 -0.\n",
      "  -0.40149618]\n",
      " ...\n",
      " [-0.          0.          0.         ...  1.24105232 -0.\n",
      "  -1.21255826]\n",
      " [-0.          0.          1.49394449 ...  0.         -0.43732833\n",
      "  -1.32092432]\n",
      " [-0.75262946  0.          1.28906129 ...  1.1665531  -0.\n",
      "  -1.13976952]]\n"
     ]
    }
   ],
   "source": [
    "# y_train = y_train.values.reshape(y_train.shape[0],1)\n",
    "# y_test = y_test.values.reshape(y_test.shape[0],1)\n",
    "nn_model = NeuralNet(X_train,y_train, h=20 )\n",
    "nn_model.train(activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.366412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.206107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.351145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.358779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54898</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.358779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54899</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.167939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54900</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.312977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54901</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.351145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54902</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.503817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54903 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  time_in_hospital  num_lab_procedures\n",
       "0      0.555556          0.153846            0.366412\n",
       "1      0.666667          0.153846            0.206107\n",
       "2      0.666667          0.461538            0.351145\n",
       "3      0.777778          0.615385            0.358779\n",
       "4      0.555556          0.000000            0.320611\n",
       "...         ...               ...                 ...\n",
       "54898  0.777778          0.307692            0.358779\n",
       "54899  0.333333          0.076923            0.167939\n",
       "54900  0.666667          0.230769            0.312977\n",
       "54901  0.777778          0.076923            0.351145\n",
       "54902  0.777778          0.384615            0.503817\n",
       "\n",
       "[54903 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
